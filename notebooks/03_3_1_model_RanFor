# âš¡ Treinamento de Modelo: Random Forest (Fase 3 - Time 7)

**ResponsÃ¡vel:** Time 7 (LIGIA)
**Algoritmo:** Random Forest

**Objetivos deste Notebook:**
1. **Carregar:** Importar e preparar os dados (Pipeline integrado).
2. **Treinar:** Ajustar o modelo Random Forest (Baseline vs Otimizado).
3. **Avaliar:** Medir performance com foco no **Recall** (Sensibilidade) e aplicar threshold de seguranÃ§a (0.41).
4. **Validar:** Teste de Fogo no grupo de risco "AssintomÃ¡tico" (Isquemia Silenciosa).

**MÃ©tricas Chave:**
* **Recall (Sensibilidade):** Prioridade mÃ¡xima. NÃ£o podemos deixar doentes irem para casa.
* **F1-Score:** Garantia de equilÃ­brio para evitar falsos positivos excessivos.

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import os
import json
import kagglehub
import shutil

# MÃ©tricas e Ferramentas
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.utils import resample
from sklearn.metrics import classification_report, confusion_matrix, recall_score, roc_auc_score, f1_score, ConfusionMatrixDisplay

# ConfiguraÃ§Ã£o visual
sns.set_theme(style="whitegrid")

# --- 1. AQUISIÃ‡ÃƒO E PREPARAÃ‡ÃƒO (Adaptado para rodar sem arquivos locais) ---
print("ğŸ”„ Preparando dados...")

# Download ou Fallback
try:
    path_cache = kagglehub.dataset_download("cherngs/heart-disease-cleveland-uci")
    arquivo_csv = [f for f in os.listdir(path_cache) if f.endswith('.csv')][0]
    df = pd.read_csv(os.path.join(path_cache, arquivo_csv))
except:
    url = "https://raw.githubusercontent.com/asthasharma98/Heart-Disease-Prediction-Deployment/master/heart_cleveland_upload.csv"
    df = pd.read_csv(url)

# DivisÃ£o X e y
X = df.drop('condition', axis=1)
y = df['condition']

# Split 80/20
X_train_raw, X_test, y_train_raw, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Balanceamento Estratificado (Upsampling no Treino)
print("âš–ï¸ Aplicando Balanceamento Estratificado...")
df_train = pd.concat([X_train_raw, y_train_raw], axis=1)
df_train['strata'] = df_train['sex'].astype(str) + "_" + df_train['condition'].astype(str)
max_size = df_train['strata'].value_counts().max()

lista_dfs = []
for grupo in df_train['strata'].unique():
    df_grupo = df_train[df_train['strata'] == grupo]
    df_res = resample(df_grupo, replace=True, n_samples=max_size, random_state=42)
    lista_dfs.append(df_res)

df_train_bal = pd.concat(lista_dfs)
X_train = df_train_bal.drop(['condition', 'strata'], axis=1)
y_train = df_train_bal['condition']

print(f"âœ… Dados prontos!")
print(f"Treino Balanceado: {X_train.shape}")
print(f"Teste: {X_test.shape}")

# --- 2. TREINAMENTO (Baseline vs Otimizado) ---

# A. Baseline
print("ğŸŒ² Treinando Baseline (PadrÃ£o)...")
model_baseline = RandomForestClassifier(random_state=42, n_jobs=-1)
model_baseline.fit(X_train, y_train)
recall_base = recall_score(y_test, model_baseline.predict(X_test))
print(f"   Recall Baseline: {recall_base:.2%}")

# B. OtimizaÃ§Ã£o (GridSearchCV)
print("\nğŸ” Iniciando busca pelos melhores parÃ¢metros (Isso pode levar alguns segundos)...")

param_grid = {
    "n_estimators": [50, 100, 200],
    "max_depth": [None, 5, 10],
    "min_samples_split": [2, 5],
    "min_samples_leaf": [1, 2],
    "max_features": ["sqrt"]
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42, n_jobs=-1),
    param_grid=param_grid,
    cv=cv,
    scoring='recall', # Foco total em nÃ£o perder doentes
    n_jobs=-1,
    verbose=0
)

grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

print("-" * 40)
print(f"ğŸ† Melhor Recall na ValidaÃ§Ã£o Cruzada: {grid_search.best_score_:.2%}")
print(f"âš™ï¸ Melhores ParÃ¢metros: {grid_search.best_params_}")

# --- 3. AVALIAÃ‡ÃƒO DE PERFORMANCE (Threshold Ajustado) ---

# Probabilidades (0 a 1)
y_proba = best_model.predict_proba(X_test)[:, 1]

# Limiar personalizado para maximizar seguranÃ§a (Conforme documento original)
limiar = 0.41
y_pred_ajustado = (y_proba >= limiar).astype(int)

recall_final = recall_score(y_test, y_pred_ajustado)

print(f"ğŸ“ˆ EvoluÃ§Ã£o do Recall no Teste:")
print(f"   - Baseline:  {recall_base:.2%}")
print(f"   - Otimizado (Limiar {limiar}): {recall_final:.2%}")

# Matriz de ConfusÃ£o
plt.figure(figsize=(6, 5))
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_ajustado, cmap='Blues', display_labels=['SaudÃ¡vel', 'Doente'])
plt.title(f'Matriz de ConfusÃ£o (Threshold {limiar})')
plt.grid(False)
plt.show()

print("\n" + classification_report(y_test, y_pred_ajustado))
print(f"AUC-ROC Score: {roc_auc_score(y_test, y_proba):.4f}")

# --- 4. VALIDAÃ‡ÃƒO NO SUBGRUPO ASSINTOMÃTICO (Teste de Fogo) ---
print(f"ğŸ•µï¸ Analisando isquemia silenciosa (Pacientes sem dor tÃ­pica)...")

# Filtrando dados: No dataset Cleveland, cp (Chest Pain) == 3 Ã© AssintomÃ¡tico
# (Nota: Adaptado do cÃ³digo original que usava One-Hot 'cp_3')
mask_assin = X_test['cp'] == 3
X_test_sub = X_test[mask_assin]
y_test_sub = y_test[mask_assin.values]

if len(X_test_sub) > 0:
    # Aplicando o limiar de seguranÃ§a
    y_proba_sub = best_model.predict_proba(X_test_sub)[:, 1]
    y_pred_sub = (y_proba_sub >= limiar).astype(int)
    
    recall_sub = recall_score(y_test_sub, y_pred_sub)
    
    print("-" * 50)
    print(f"RESULTADO DO TESTE DE FOGO (Limiar {limiar}):")
    print(f"   Pacientes AssintomÃ¡ticos no Teste: {len(X_test_sub)}")
    print(f"   Recall (Doentes detectados): {recall_sub:.2%}")
    print("-" * 50)
    
    if recall_sub > 0.85:
        print("âœ… SUCESSO: O modelo Ã© excelente em detectar isquemia silenciosa!")
    else:
        print("âš ï¸ ATENÃ‡ÃƒO: O recall caiu neste grupo. Considere baixar ainda mais o limiar.")
else:
    print("Nenhum paciente assintomÃ¡tico na amostra de teste.")

# --- 5. EXPORTAÃ‡ÃƒO DO MODELO ---
os.makedirs('models', exist_ok=True)

# 1. Salva o Modelo .pkl
caminho_final = 'models/modelo_RandomForest_Otimizado.pkl'
joblib.dump(best_model, caminho_final)

# 2. Salva o Metadata (Crucial para a aplicaÃ§Ã£o saber o threshold)
metadata = {
    "algoritmo": "RandomForestClassifier",
    "threshold_otimizado": limiar,
    "input_features": list(X.columns)
}

with open('models/metadata_RandomForest.json', 'w') as f:
    json.dump(metadata, f)

print(f"ğŸ’¾ Modelo salvo em: {caminho_final}")
print(f"ğŸ“„ Metadata salvo (Threshold {limiar} registrado).")
