# üè• Projeto LIGIA - Time 7: Triagem Card√≠aca com Random Forest

Este notebook documenta o pipeline completo de treinamento, valida√ß√£o e relat√≥rio t√©cnico do modelo de Intelig√™ncia Artificial desenvolvido para auxiliar na triagem de risco card√≠aco em UPAs.

**Metodologia:**
1. **Coleta:** Dataset *Cleveland Heart Disease* (UCI).
2. **Preparo:** Divis√£o 80/20 e Balanceamento Estratificado (Upsampling).
3. **Modelagem:** Teste de hiperpar√¢metros (10 a 500 √°rvores).
4. **Avalia√ß√£o:** Foco em Sensibilidade (Recall) para seguran√ßa do paciente.

# Instala√ß√£o silenciosa da biblioteca do Kaggle (caso n√£o exista)
try:
    import kagglehub
except ImportError:
    !pip install -q kagglehub
    import kagglehub

import pandas as pd
import numpy as np
import os
import shutil
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.utils import resample
from sklearn.metrics import recall_score, accuracy_score, f1_score, confusion_matrix

# Configura√ß√£o de estilo dos gr√°ficos
sns.set_theme(style="whitegrid")
print("‚úÖ Ambiente configurado com sucesso.")

# --- 1. AQUISI√á√ÉO DE DADOS ---
print("üîÑ Buscando dataset...")
try:
    # Tenta baixar via KaggleHub
    path_cache = kagglehub.dataset_download("cherngs/heart-disease-cleveland-uci")
    arquivo_csv = [f for f in os.listdir(path_cache) if f.endswith('.csv')][0]
    df = pd.read_csv(os.path.join(path_cache, arquivo_csv))
    print("‚úÖ Download via Kaggle conclu√≠do.")
except:
    # Fallback: URL direta caso o Kaggle falhe
    print("‚ö†Ô∏è Kaggle indispon√≠vel. Usando mirror alternativo...")
    url = "https://raw.githubusercontent.com/asthasharma98/Heart-Disease-Prediction-Deployment/master/heart_cleveland_upload.csv"
    df = pd.read_csv(url)
    print("‚úÖ Download via Mirror conclu√≠do.")

# --- 2. DIVIS√ÉO TREINO/TESTE ---
X = df.drop('condition', axis=1)
y = df['condition']

# Divis√£o 80/20 com semente fixa para reprodutibilidade
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 3. BALANCEAMENTO ESTRATIFICADO (S√ì NO TREINO) ---
print("\n‚öñÔ∏è Aplicando Balanceamento Estratificado (Upsampling)...")

# Junta X e y temporariamente
df_train = pd.concat([X_train, y_train], axis=1)

# Cria "strata" combinando Sexo + Condi√ß√£o para garantir que minorias sejam representadas
# Ex: Mulheres Doentes (grupo raro) ser√£o multiplicadas
df_train['strata'] = df_train['sex'].astype(str) + "_" + df_train['condition'].astype(str)
max_size = df_train['strata'].value_counts().max()

lista_dfs = []
for grupo in df_train['strata'].unique():
    df_grupo = df_train[df_train['strata'] == grupo]
    # Upsampling com reposi√ß√£o
    df_res = resample(df_grupo, replace=True, n_samples=max_size, random_state=42)
    lista_dfs.append(df_res)

# Reconstr√≥i o treino final
df_train_bal = pd.concat(lista_dfs)
X_train_bal = df_train_bal.drop(['condition', 'strata'], axis=1)
y_train_bal = df_train_bal['condition']

print(f"üìä Linhas Originais de Treino: {len(X_train)}")
print(f"üìä Linhas Balanceadas de Treino: {len(X_train_bal)} (Pronto para modelagem)")

# Lista de configura√ß√µes para testar
lista_arvores = [10, 50, 100, 200, 500]
resultados = []

print("üß† Iniciando treinamento de modelos...")
print(f"{'Arvores':<10} | {'Acur√°cia':<10} | {'Recall':<10} | {'F1-Score':<10}")
print("-" * 46)

for n in lista_arvores:
    # Treina no Balanceado, Testa no Original (X_test)
    modelo = RandomForestClassifier(n_estimators=n, random_state=42)
    modelo.fit(X_train_bal, y_train_bal)
    previsoes = modelo.predict(X_test)

    acc = accuracy_score(y_test, previsoes)
    rec = recall_score(y_test, previsoes)
    f1 = f1_score(y_test, previsoes)

    resultados.append({
        'arvores': n,
        'acuracia': acc,
        'recall': rec,
        'f1': f1,
        'model_obj': modelo
    })
    
    print(f"{n:<10} | {acc:.1%}    | {rec:.1%}    | {f1:.1%}")

# Sele√ß√£o do Campe√£o: Melhor F1, com Recall como desempate
campeao = sorted(resultados, key=lambda x: (x['f1'], x['recall']), reverse=True)[0]
modelo_final = campeao['model_obj']
y_pred_final = modelo_final.predict(X_test)

# Dados para o relat√≥rio
matriz = confusion_matrix(y_test, y_pred_final)
vn, fp, fn, vp = matriz.ravel()
total_pacientes = vn + fp + fn + vp

### üìÑ An√°lise T√©cnica do Modelo

A **Random Forest** utiliza m√∫ltiplas √°rvores de decis√£o simult√¢neas para reduzir o risco de erro humano e overfitting. O objetivo deste modelo √© atuar como uma segunda opini√£o de seguran√ßa em UPAs.

**Destaques da Estrat√©gia:**
* **Balanceamento Estratificado:** A IA estudou a mesma quantidade de casos para 4 grupos distintos (Homens Saud√°veis/Doentes, Mulheres Saud√°veis/Doentes). Isso reduz o vi√©s hist√≥rico e melhora a detec√ß√£o em mulheres.
* **Hierarquia de Sintomas:** O modelo validou que *Dor no Peito (cp)* e *Talassemia (thal)* continuam sendo os maiores preditores de risco card√≠aco.

print("\n" + "="*80)
print(f"{'üìÑ RELAT√ìRIO T√âCNICO DE INTELIG√äNCIA ARTIFICIAL - LIGIA TIME 7':^80}")
print("="*80)

print(f"\n1. RESUMO EXECUTIVO")
print(f"Modelo de triagem card√≠aca otimizado via F1-Score para maximizar a seguran√ßa.")
print(f"‚Ä¢ Configura√ß√£o Vencedora: Random Forest com {campeao['arvores']} √°rvores.")
print(f"‚Ä¢ Dados: Divis√£o 80/20 com Balanceamento Estratificado.")

print(f"\n2. PERFORMANCE DO MELHOR MODELO (M√©tricas na Prova Real)")
print(f"-"*60)
print(f"  M√âTRICA                  | VALOR OBTIDO  | INTERPRETA√á√ÉO")
print(f"-"*60)
print(f"  ü©∫ Recall (Sensibilidade) | {campeao['recall']:>6.2%}        | De cada 100 doentes, detectamos {campeao['recall']*100:.0f}.")
print(f"  üéØ Acur√°cia Global        | {campeao['acuracia']:>6.2%}        | Taxa geral de acertos.")
print(f"  ‚öñÔ∏è F1-Score               | {campeao['f1']:>6.2%}        | Equil√≠brio precis√£o/recall.")
print(f"-"*60)

print(f"\n3. AN√ÅLISE DE ERRO (Matriz de Confus√£o)")
print(f"Total de pacientes testados: {total_pacientes}")
print(f"\n   [ REALIDADE ]")
print(f"         |   Saud√°vel   |    Doente    |")
print(f" PRED    |--------------|--------------|")
print(f" I  Saud |      {vn:<2}      |      {fn:<2}      | <-- Falsos Negativos (Risco Cr√≠tico)")
print(f" √á  Doen |      {fp:<2}      |      {vp:<2}      | <-- Verdadeiros Positivos (Sucesso)")
print(f" √É  -----|--------------|--------------|")
print(f" O")

print(f"\n >> CONCLUS√ÉO CL√çNICA:")
if fn == 0:
    print(f" ‚úÖ EXCELENTE: Risco zero de alta indevida (0 Falsos Negativos).")
elif fn <= 3:
    print(f" ‚úÖ BOM: Apenas {fn} caso(s) perdido(s). Triagem humana atua como backup.")
else:
    print(f" ‚ö†Ô∏è ATEN√á√ÉO: Perda de {fn} casos. Necess√°rio ajuste de threshold.")

print(f"\n4. FATORES DECISIVOS (Feature Importance)")
importancias = pd.Series(modelo_final.feature_importances_, index=X.columns).sort_values(ascending=False).head(3)
for i, (nome, valor) in enumerate(importancias.items(), 1):
    print(f"  {i}¬∫ Fator: {nome.upper()} (Impacto: {valor:.1%})")

print("\n" + "="*80)

plt.figure(figsize=(7, 5))
sns.heatmap(matriz, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Pred: Saud√°vel', 'Pred: Doente'],
            yticklabels=['Real: Saud√°vel', 'Real: Doente'])
plt.title('Matriz de Confus√£o Visual')
plt.ylabel('Realidade')
plt.xlabel('Previs√£o do Modelo')
plt.show()
